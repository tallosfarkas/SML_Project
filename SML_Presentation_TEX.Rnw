\documentclass[aspectratio=169]{beamer}
\usetheme{Madrid}
\usecolortheme{beaver}

\title[SML Project]{Predicting S\&P 500 Direction with Ensemble Methods}
\author{Christian Weißmeier \and Farkas Tallos}
\institute[WU Wien]{Statistical and Machine Learning (2025/26)}
\date{\today}

% LaTeX packages for tables and graphics
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}

% Beamer options for cleaner look
\setbeamertemplate{navigation symbols}{}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\setbeamercolor{block body}{bg=lightgray}
\setbeamerfont{frametitle}{size=\large}
\setbeamerfont{block title}{size=\small}
\setbeamerfont{normal text}{size=\small}

\begin{document}

% --- Title Slide ---
\begin{frame}
  \titlepage
\end{frame}

% --- Agenda ---
\begin{frame}
  \frametitle{Agenda}
  \tableofcontents
\end{frame}

%-------------------------------------------------------
\begin{frame}{Motivation}
\center{
\begin{quote}
“Stock returns are predictable, but not by much.”\\[3mm]
\hfill \footnotesize — John H. Cochrane, \textit{Asset Pricing (2005)}
\end{quote}
}
\begin{itemize}
  \item Forecasting stock market direction is one of the most classical and challenging tasks in finance.
  \item Weak predictability can matter for portfolio allocation and risk management. \\

  \vspace{0.3cm}

  \textbf{Our Set-Up:}
  \vspace{0.1cm}
  \item We focus on predicting whether the S\&P 500 index goes \textbf{Up} or \textbf{Down} next month.
  \item We evaluate statistical learning methods in a time-series context.
  \item Introduce the role of regularization and nonlinear models.
  \item Compare linear vs. nonlinear classification models (Elastic Net vs. Random Forest).
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Data Overview}
\begin{itemize}
  \item We created our own monthly dataset from S\&P 500, FRED, and FRBSF data banks (1990–today).
  \item \textbf{Target:} Monthly S\&P 500 market direction (\textbf{UP} or \textbf{DOWN}) in \(t + 1\).
  \item \textbf{Predictors:}
  \begin{enumerate}
    \item \textbf{Market data:} Lagged S\&P 500 returns (up to five months) and trading volume changes.
    \item \textbf{Macroeconomic indicators:} CPI, Federal Funds Rate, NBER recession dummy.
    \item \textbf{Volatility:} Lagged changes in the VIX index.
    \item \textbf{Sentiment:} Daily News Sentiment Index.
  \end{enumerate}
  \item All features are lagged to avoid look-ahead bias.
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Stationarity Considerations}
\begin{itemize}
  \item Most macro-financial time series are \textbf{non-stationary} in levels.
  \item We therefore use:
  \begin{itemize}
    \item \textbf{Lagged returns} instead of prices.
    \item \textbf{Changes} in VIX and sentiment rather than levels.
    \item \textbf{Changes in macro variables} to preserve temporal causality.
  \end{itemize}
  \item This transformation makes features approximately stationary, ensuring:
  \begin{itemize}
    \item Stable model coefficients over time.
    \item Valid cross-validation across time periods.
  \end{itemize}
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Hyperparameter Tuning: Time-Series Cross-Validation}
\footnotesize

\begin{itemize}
  \item[] \textbf{Why not standard cross-validation?}
  \begin{itemize}
    \item Random $k$-fold CV assumes i.i.d.\ data.
    \item Time-series data exhibit autocorrelation $\Rightarrow$ temporal dependence.
    \item Random shuffling lets the model ``see the future'' $\Rightarrow$ data leakage and over-optimism.
  \end{itemize}

  \vspace{0.4em}
  \item[] \textbf{Our method: Rolling-window time-series CV}
  \begin{itemize}
    \item Construct a hyperparameter grid:
      \begin{itemize}
        \item Elastic Net: $\alpha$ and $\lambda$ grid.
        \item Random Forest: \texttt{mtry}, \texttt{min.node.size}, \texttt{max.depth}, \texttt{sample.fraction}.
      \end{itemize}
    \item Use a chronological window structure:
      \begin{itemize}
        \item Initial training window: 60 months (5 years).
        \item Validation horizon: 12 months (1 year).
        \item Fixed-length rolling window moving forward in time.
      \end{itemize}
    \item For each fold:
      \begin{itemize}
        \item Fit model only on past data and predict the next 12 months.
        \item Record accuracy and AUC on the validation slice.
      \end{itemize}
  \end{itemize}
  \item[] \textbf{Result:}
  \begin{itemize}
    \item Select the hyperparameters achieving the \textbf{highest mean AUC across all rolling folds}.
    \item Prevents look-ahead bias and mimics real-time forecasting.
  \end{itemize}
\end{itemize}

\end{frame}
%-------------------------------------------------------


\begin{frame}{Class Imbalance, Threshold Adjustment \& AUC}

\begin{columns}[T, totalwidth=\textwidth]
  % Left: Plot
  \begin{column}{0.45\textwidth}
    \begin{center}
      \includegraphics[width=0.75\linewidth]{imbalance_plot.png}\\[0.3em]
      \footnotesize{Class imbalance in monthly S\&P 500 direction}
    \end{center}
  \end{column}

  % Right: Logic + AUC explanation
  \begin{column}{0.55\textwidth}
    \footnotesize
    \begin{itemize}
      \item Dependent variable \texttt{UP\_DOWN} is imbalanced.
      \item A naive classifier that would always predict ``Up'' would achieve high accuracy.
      \item A simple threshold of \(0.5\) reduces the accuracy. \\

      \vspace{0.1em}

      $\Rightarrow$ \textbf{Accuracy alone is misleading.}
    \end{itemize}

    \textbf{Threshold adjustment (Youden's J):}
    \[
      t^\ast = \arg\max_{t} \big\{ \text{Sensitivity}(t) + \text{Specificity}(t) - 1 \big\}
    \]
    \vspace{-1.2em}
    \begin{itemize}
      \item We tune $t^\ast$ on the \textbf{training set} using the ROC curve.
      \item Then apply this fixed threshold to the \textbf{test set} for true OoS evaluation.
    \end{itemize}

    \textbf{AUC is robust here:}
    \begin{itemize}
      \item ROC/AUC depends on the \emph{ranking} of predicted probabilities, not on class proportions. \\
      $\Rightarrow$ \textbf{AUC is invariant to class imbalance} and a suitable metric for our setting.
    \end{itemize}
  \end{column}
\end{columns}

\end{frame}

%-------------------------------------------------------
\begin{frame}{Elastic Net Logistic Regression}
\small
\textbf{Model Intuition:}
\begin{itemize}
  \item We model the probability of an \textbf{Up} move using a logistic function:
  \[
  P(Y_t = 1 \mid X_t) = \frac{1}{1 + e^{-(\beta_0 + X_t \beta)}}
  \]
  \item Coefficients \(\beta\) are maximum likelihood estimates under a regularization penalty to prevent overfitting and perform variable selection.
\end{itemize}

\vspace{0.3cm}

\textbf{Elastic Net Regularization:}
\[
\min_{\beta} \left[
  -\ell(\beta)
  + \lambda \left(
      (1 - \alpha)\frac{\|\beta\|_2^2}{2}
      + \alpha \|\beta\|_1
    \right)
\right]
\]

\begin{itemize}
  \item \(\ell(\beta)\): log-likelihood of the logistic model.
  \item \(\lambda\): overall penalty strength controlling coefficient shrinkage.
  \item \(\alpha\): mixes the two types of regularization:
  \begin{itemize}
    \item Ridge (L2): smooth shrinkage.
    \item Lasso (L1): sets some coefficients exactly to zero.
  \end{itemize}
\end{itemize}
\end{frame}

%-------------------------------------------------------



%-------------------------------------------------------
\begin{frame}{3. Methodology: Model Assessment Strategy}
\framesubtitle{The most critical methodological slide}

\begin{block}{The Problem: Time-Series Data}
Standard \(K\)-fold CV shuffles data randomly, “peeking into the future” and violating temporal order.
This leads to overly optimistic results.
\end{block}

\pause

\begin{block}{Our Solution: Two-Level Chronological Split}
\begin{itemize}
  \item \textbf{Level 1: Train/Test Split (for Assessment)}
  \begin{itemize}
    \item Chronological 70/30 split.
    \item \textbf{Train:} 1990–2014 (used for tuning).
    \item \textbf{Test:} 2015–2025 (used once for final evaluation).
  \end{itemize}
  \pause
  \item \textbf{Level 2: Rolling-Window CV (for Tuning)}
  \begin{itemize}
    \item Within the 70\% training set, perform rolling-window validation.
    \item Simulates real-world use: train on past, predict the future.
  \end{itemize}
\end{itemize}
\end{block}
\end{frame}

\end{document}
