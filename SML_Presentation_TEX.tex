\documentclass[aspectratio=169]{beamer}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlsng}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hldef}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usetheme{Madrid}
\usecolortheme{beaver}

\title[SML Project]{Predicting S\&P 500 Direction with Ensemble Methods}
\author{Christian Weißmeier \and Farkas Tallos}
\institute[WU Wien]{Statistical and Machine Learning (2025/26)}
\date{\today}

% LaTeX packages for tables and graphics
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}

% Beamer options for cleaner look
\setbeamertemplate{navigation symbols}{}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\setbeamercolor{block body}{bg=lightgray}
\setbeamerfont{frametitle}{size=\large}
\setbeamerfont{block title}{size=\small}
\setbeamerfont{normal text}{size=\small}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

% --- Title Slide ---
\begin{frame}
  \titlepage
\end{frame}

% --- Agenda ---
\begin{frame}
  \frametitle{Agenda}
  \tableofcontents
\end{frame}

%-------------------------------------------------------
\begin{frame}{Motivation}
\center{
\begin{quote}
“Stock returns are predictable, but not by much.”\\[3mm]
\hfill \footnotesize — John H. Cochrane, \textit{Asset Pricing (2005)}
\end{quote}
}
\begin{itemize}
  \item Forecasting stock market direction is one of the most classical and challenging tasks in finance.
  \item Weak predictability can matter for portfolio allocation and risk management. \\

  \vspace{0.3cm}

  \textbf{Our Set-Up:}
  \vspace{0.1cm}
  \item We focus on predicting whether the S\&P 500 index goes \textbf{Up} or \textbf{Down} next month.
  \item We evaluate statistical learning methods in a time-series context.
  \item Introduce the role of regularization and nonlinear models.
  \item Compare linear vs. nonlinear classification models (Elastic Net vs. Random Forest).
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Data Overview}
\begin{itemize}
  \item We created our own monthly dataset from S\&P 500, FRED, and FRBSF data banks (1990–today).
  \item \textbf{Target:} Monthly S\&P 500 market direction (\textbf{UP} or \textbf{DOWN}) in \(t + 1\).
  \item \textbf{Predictors:}
  \begin{enumerate}
    \item \textbf{Market data:} Lagged S\&P 500 returns (up to five months) and trading volume changes.
    \item \textbf{Macroeconomic indicators:} CPI, Federal Funds Rate, NBER recession dummy.
    \item \textbf{Volatility:} Lagged changes in the VIX index.
    \item \textbf{Sentiment:} Daily News Sentiment Index.
  \end{enumerate}
  \item All features are lagged to avoid look-ahead bias.
\end{itemize}
\end{frame}

\begin{frame}{Exploratory Analysis: Feature Relationships}

\begin{columns}[T, totalwidth=\textwidth]

  % Left: Plot
  \begin{column}{0.50\textwidth}
    \includegraphics[width=0.9\linewidth]{pair_plot.png} \\
    {\footnotesize Pairwise correlations and marginal distributions.}
  \end{column}

  % Right: Key insights
  \begin{column}{0.50\textwidth}
    \footnotesize
    \textbf{Why these predictors may matter:}
    \begin{itemize}
        \item \textbf{Macro indicators} (CPI, Fed Funds Rate, NBER) affect discount rates and expected returns.
        \item \textbf{Lagged returns} reflect momentum and reversal effects.
        \item \textbf{Volatility} (VIX) captures uncertainty and risk sentiment.
        \item \textbf{Sentiment} (DNSI) reflects investor expectations and behavioral biases.
    \end{itemize}

    \vspace{0.5em}
    \textbf{Empirical observation:}
    \begin{itemize}
        \item Weak linear correlations $\Rightarrow$ low-signal, non-linear problem.
        \item Several predictors show significant \textbf{ multicollinearity}.
        \item Motivates using \textbf{Elastic Net}, \textbf{Random Forests}, and \textbf{Gradient Boosting}.
    \end{itemize}
  \end{column}

\end{columns}

\end{frame}
%-------------------------------------------------------
\begin{frame}{Stationarity Considerations}
\begin{itemize}
  \item Most macro-financial time series are \textbf{non-stationary} in levels.
  \item We therefore use:
  \begin{itemize}
    \item \textbf{Lagged returns} instead of prices.
    \item \textbf{Changes} in VIX and sentiment rather than levels.
    \item \textbf{Changes in macro variables} to preserve temporal causality.
  \end{itemize}
  \item This transformation makes features approximately stationary, ensuring:
  \begin{itemize}
    \item Stable model coefficients over time.
    \item Valid cross-validation across time periods.
  \end{itemize}
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Hyperparameter Tuning: Time-Series Cross-Validation}
\footnotesize

\begin{itemize}
  \item[] \textbf{Why not standard cross-validation?}
  \begin{itemize}
    \item Random $k$-fold CV assumes i.i.d.\ data.
    \item Time-series data exhibit autocorrelation $\Rightarrow$ temporal dependence.
    \item Random shuffling lets the model ``see the future'' $\Rightarrow$ data leakage and over-optimism.
  \end{itemize}

  \vspace{0.4em}
  \item[] \textbf{Our method: Rolling-window time-series CV}
  \begin{itemize}
    \item Construct a hyperparameter grid:
      \begin{itemize}
        \item Elastic Net: $\alpha$ and $\lambda$ grid.
        \item Random Forest: \texttt{mtry}, \texttt{min.node.size}, \texttt{max.depth}, \texttt{sample.fraction}.
      \end{itemize}
    \item Use a chronological window structure:
      \begin{itemize}
        \item Initial training window: 60 months (5 years).
        \item Validation horizon: 12 months (1 year).
        \item Fixed-length rolling window moving forward in time.
      \end{itemize}
    \item For each fold:
      \begin{itemize}
        \item Fit model only on past data and predict the next 12 months.
        \item Record accuracy and AUC on the validation slice.
      \end{itemize}
  \end{itemize}
  \item[] \textbf{Result:}
  \begin{itemize}
    \item Select the hyperparameters achieving the \textbf{highest mean AUC across all rolling folds}.
    \item Prevents look-ahead bias and mimics real-time forecasting.
  \end{itemize}
\end{itemize}

\end{frame}
%-------------------------------------------------------

\begin{frame}{Class Imbalance, Threshold Adjustment \& AUC}

\begin{columns}[T, totalwidth=\textwidth]
  % Left: Plot
  \begin{column}{0.45\textwidth}
    \begin{center}
      \includegraphics[width=0.75\linewidth]{imbalance_plot.png}\\[0.3em]
      \footnotesize{Class imbalance in monthly S\&P 500 direction}
    \end{center}
  \end{column}

  % Right: Logic + AUC explanation
  \begin{column}{0.55\textwidth}
    \footnotesize
    \begin{itemize}
      \item Dependent variable \texttt{UP\_DOWN} is imbalanced.
      \item A naive classifier that would always predict ``Up'' would achieve high accuracy.
      \item A simple threshold of \(0.5\) reduces the accuracy. \\

      \vspace{0.1em}

      $\Rightarrow$ \textbf{Accuracy alone is misleading.}
    \end{itemize}

    \textbf{Threshold adjustment (Youden's J):}
    \[
      t^\ast = \arg\max_{t} \big\{ \text{Sensitivity}(t) + \text{Specificity}(t) - 1 \big\}
    \]
    \vspace{-1.2em}
    \begin{itemize}
      \item We tune $t^\ast$ on the \textbf{training set} using the ROC curve.
      \item Then apply this fixed threshold to the \textbf{test set} for true OoS evaluation.
    \end{itemize}

    \textbf{AUC is robust here:}
    \begin{itemize}
      \item ROC/AUC depends on the \emph{ranking} of predicted probabilities, not on class proportions. \\
      $\Rightarrow$ \textbf{AUC is invariant to class imbalance} and a suitable metric for our setting.
    \end{itemize}
  \end{column}
\end{columns}

\end{frame}

%-------------------------------------------------------
\begin{frame}{Elastic Net Logistic Regression}
\small
\textbf{Model Intuition:}
\begin{itemize}
  \item We model the probability of an \textbf{Up} move using a logistic function:
  \[
  P(Y_t = 1 \mid X_t) = \frac{1}{1 + e^{-(\beta_0 + X_t \beta)}}
  \]
  \item Coefficients \(\beta\) are maximum likelihood estimates under a regularization penalty to prevent overfitting and perform variable selection.
\end{itemize}

\vspace{0.3cm}

\textbf{Elastic Net Regularization:}
\[
\min_{\beta} \left[
  -\ell(\beta)
  + \lambda \left(
      (1 - \alpha)\frac{\|\beta\|_2^2}{2}
      + \alpha \|\beta\|_1
    \right)
\right]
\]

\begin{itemize}
  \item \(\ell(\beta)\): log-likelihood of the logistic model.
  \item \(\lambda\): overall penalty strength controlling coefficient shrinkage.
  \item \(\alpha\): mixes the two types of regularization:
  \begin{itemize}
    \item Ridge (L2): smooth shrinkage.
    \item Lasso (L1): sets some coefficients exactly to zero.
  \end{itemize}
\end{itemize}
\end{frame}


%-------------------------------------------------------
\begin{frame}{Elastic Net: Out-of-Sample Performance}

\small
\textbf{Predictive performance (test set):}
\footnotesize{
\begin{itemize}
  \item Accuracy: \textbf{64.3\%}
  \item AUC: \textbf{0.79} (strong probability ranking ability)
  \item Threshold tuned : \(t^*= 0.6743 \) \(\rightarrow\) The model avoids overly optimistic Up predictions
\end{itemize}
}


\small{\textbf{Confusion matrix:}}
\footnotesize{
\begin{center}
\begin{tabular}{c|cc}
              & Actual 0 & Actual 1 \\
\hline
Predicted 0   & 36       & 38       \\
Predicted 1   & 8        & 47       \\
\end{tabular}
\end{center}
}

\small{\textbf{Interpretation:}}
\footnotesize{
\begin{itemize}
  \item \textbf{Specificity} (correct Down predictions):
            $36/44 \approx \textbf{82\%}$
            $\Rightarrow$ we correctly flag most Down months.
  \item \textbf{Sensitivity} (correct Up predictions):
            $47/85 \approx \textbf{55\%}$
            $\Rightarrow$ we still capture the majority of Up months.
  \item The model trades a small loss in raw accuracy for a much better
        \textbf{balance} between detecting costly Down markets and
        still identifying Up markets, which is desirable in an
        asset-management context.
\end{itemize}
}
\end{frame}

%-------------------------------------------------------

\begin{frame}{Elastic Net: Selected Predictors and Probability Ranking}

\small
\begin{columns}[T, totalwidth=\textwidth]

  % Left: Coefficients
  \begin{column}{0.52\textwidth}
  \centering{
    \includegraphics[width=0.75\linewidth]{enet_coeffs.png}
}
    {\scriptsize
    \begin{itemize}
    \item  Coeff. represent changes in the \textbf{odds} of an ``Up'' month.
    \item  Elastic Net highlights variables with consistent signal.
    \item  Momentum is a major driver of Up probabilities.
    \item  Sentiment matters more during recession periods.
    \end{itemize}
    }

  \end{column}

  % Right: ROC Curve
  \begin{column}{0.5\textwidth}
  \centering{
    \includegraphics[width=0.78\linewidth]{roc_enet.png}
} \\
\vspace{1.75em}
    {\scriptsize
    \begin{itemize}
    \item \textbf{AUC = 0.79}: strong discriminative ability despite low-signal, noisy financial data.
    \item ROC curve well above diagonal $\Rightarrow$ model ranks Up vs.\ Down months effectively.
    \end{itemize}}
  \end{column}
\end{columns}

\end{frame}

%-------------------------------------------------------

\begin{frame}{Random Forest: Out-of-Sample Performance}

\small
\textbf{Predictive performance (test set):}
\footnotesize{
\begin{itemize}
  \item Accuracy: \textbf{71.3\%}
  \item AUC: \textbf{0.753} (strong non-linear discriminative ability)
  \item RF produces well-calibrated probability scores without threshold tuning
\end{itemize}
}

\small{\textbf{Confusion matrix:}}
\footnotesize{
\begin{center}
\begin{tabular}{c|cc}
              & Actual 0 & Actual 1 \\
\hline
Predicted 0   & 29       & 22       \\
Predicted 1   & 15       & 63       \\
\end{tabular}
\end{center}
}

\small{\textbf{Interpretation:}}
\footnotesize{
\begin{itemize}
  \item \textbf{Specificity} (correct Down predictions):
        $29/44 \approx \textbf{66\%}$.
        RF detects a meaningful fraction of negative weeks.
  \item \textbf{Sensitivity} (correct Up predictions):
        $63/85 \approx \textbf{74\%}$.
        RF identifies most positive-return weeks.
  \item \textbf{Overall}: RF captures important \textbf{nonlinear return patterns},
        outperforming Elastic Net in accuracy and maintaining a strong AUC.
\end{itemize}
}

\end{frame}

%-------------------------------------------------------

\begin{frame}{Random Forest: Minimal Depth, Interpretation, and AUC}

\small
\begin{columns}[T, totalwidth=\textwidth]

%---------------------------------------------------
% LEFT COLUMN — Plot + Explanation + Interpretation
%---------------------------------------------------
\begin{column}{0.5\textwidth}

\centering{
  \includegraphics[width=0.78\linewidth]{rf_minimal_depth.png}
}

{\footnotesize \textbf{Explanation and Interpretation of Minimal Depth}}
{\scriptsize
\begin{itemize}
  \item Min. depth measures how \textbf{early} a variable is used in the tree.
  \item \textbf{VIX\_change\_lag} is the dominant signal
  \item \textbf{Lagged returns} are meaningful momentum predictors.
  \item Overall: RF relies mainly on \textbf{volatility shocks} and
        \textbf{recent price dynamics}.
\end{itemize}
}

\end{column}

%---------------------------------------------------
% RIGHT COLUMN — ROC + Takeaway
%---------------------------------------------------

\begin{column}{0.45\textwidth}

\centering{
  \includegraphics[width=0.8\linewidth]{roc_rf.png}
}

\raggedright

\vspace{0.1cm}

\footnotesize{ \textbf{AUC}} \\
\scriptsize{
\begin{itemize}
  \item \textbf{AUC = 0.753}
        $\Rightarrow$ strong discriminative ability and reliable ranking
        of Up vs.\ Down weeks.
\end{itemize}
}


\vspace{0.1cm}

\footnotesize{ \textbf{Takeaway}} \\
\scriptsize{
\begin{itemize}
\item Random Forest effectively captures nonlinear interactions between
\textbf{volatility movements} and \textbf{short-term momentum}.
\end{itemize}
}

\end{column}

\end{columns}

\end{frame}



%-------------------------------------------------------
%-------------------------------------------------------
\begin{frame}{3. Methodology: Model Assessment Strategy}
\framesubtitle{The most critical methodological slide}

\begin{block}{The Problem: Time-Series Data}
Standard \(K\)-fold CV shuffles data randomly, “peeking into the future” and violating temporal order.
This leads to overly optimistic results.
\end{block}

\pause

\begin{block}{Our Solution: Two-Level Chronological Split}
\begin{itemize}
  \item \textbf{Level 1: Train/Test Split (for Assessment)}
  \begin{itemize}
    \item Chronological 70/30 split.
    \item \textbf{Train:} 1990–2014 (used for tuning).
    \item \textbf{Test:} 2015–2025 (used once for final evaluation).
  \end{itemize}
  \pause
  \item \textbf{Level 2: Rolling-Window CV (for Tuning)}
  \begin{itemize}
    \item Within the 70\% training set, perform rolling-window validation.
    \item Simulates real-world use: train on past, predict the future.
  \end{itemize}
\end{itemize}
\end{block}
\end{frame}

\end{document}
