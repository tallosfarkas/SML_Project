\documentclass[aspectratio=169]{beamer}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlsng}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hldef}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usetheme{Madrid}
\usecolortheme{beaver}

\title[SML Project]{Predicting S\&P 500 Direction with Ensemble Methods}
\author{Christian Weißmeier \and Farkas Tallos}
\institute[WU Wien]{Statistical and Machine Learning (2025/26)}
\date{\today}

% LaTeX packages for tables and graphics
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}

% Beamer options for cleaner look
\setbeamertemplate{navigation symbols}{}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\setbeamercolor{block body}{bg=lightgray}
\setbeamerfont{frametitle}{size=\large}
\setbeamerfont{block title}{size=\small}
\setbeamerfont{normal text}{size=\small}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

% --- Title Slide ---
\begin{frame}
  \titlepage
\end{frame}

% --- Agenda ---
\begin{frame}
  \frametitle{Agenda}
  \tableofcontents
\end{frame}

%-------------------------------------------------------
\begin{frame}{Motivation}
\center{
\begin{quote}
“Stock returns are predictable, but not by much.”\\[3mm]
\hfill \footnotesize — John H. Cochrane, \textit{Asset Pricing (2005)}
\end{quote}
}
\begin{itemize}
  \item Forecasting stock market direction is one of the most classical and challenging tasks in finance.
  \item Weak predictability can matter for portfolio allocation and risk management. \\

  \vspace{0.3cm}

  \textbf{Our Set-Up:}
  \vspace{0.1cm}
  \item We focus on predicting whether the S\&P 500 index goes \textbf{Up} or \textbf{Down} next month.
  \item We evaluate statistical learning methods in a time-series context.
  \item Introduce the role of regularization and nonlinear models.
  \item Compare linear vs. nonlinear classification models (Elastic Net vs. Random Forest).
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Data Overview}
\begin{itemize}
  \item We created our own monthly dataset from S\&P 500, FRED, and FRBSF data banks (1990–today).
  \item \textbf{Target:} Monthly S\&P 500 market direction (\textbf{UP} or \textbf{DOWN}) in \(t + 1\).
  \item \textbf{Predictors:}
  \begin{enumerate}
    \item \textbf{Market data:} Lagged S\&P 500 returns (up to five months) and trading volume changes.
    \item \textbf{Macroeconomic indicators:} CPI, Federal Funds Rate, NBER recession dummy.
    \item \textbf{Volatility:} Lagged changes in the VIX index.
    \item \textbf{Sentiment:} Daily News Sentiment Index.
  \end{enumerate}
  \item All features are lagged to avoid look-ahead bias.
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Stationarity Considerations}
\begin{itemize}
  \item Most macro-financial time series are \textbf{non-stationary} in levels.
  \item We therefore use:
  \begin{itemize}
    \item \textbf{Lagged returns} instead of prices.
    \item \textbf{Changes} in VIX and sentiment rather than levels.
    \item \textbf{Changes in macro variables} to preserve temporal causality.
  \end{itemize}
  \item This transformation makes features approximately stationary, ensuring:
  \begin{itemize}
    \item Stable model coefficients over time.
    \item Valid cross-validation across time periods.
  \end{itemize}
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Hyperparameter Tuning: Time-Series CV}
\begin{itemize}
  \item \textbf{Why not standard cross-validation?}
  \begin{itemize}
    \item Random \(k\)-fold CV assumes i.i.d. data.
    \item Time-series data exhibit autocorrelation \(\Rightarrow\) temporal dependence.
    \item Randomly shuffling would let the model “see the future” \(\Rightarrow\) data leakage and over-optimism.
  \end{itemize}
  \vspace{0.1cm}
  \item \textbf{Improvement: Rolling-window cross-validation}
  \begin{itemize}
    \item Create a hyperparameter grid for cross-validation.
    \item Initial training window: 60 months (\(\approx 5\) years).
    \item Validation horizon: 12 months (\(\approx 1\) year).
    \item Fixed-length rolling window moving forward in time.
    \item Evaluate accuracy and AUC per fold.
  \end{itemize}
  \vspace{0.1cm}
  \item \textbf{Result:} Choose the best hyperparameters by highest mean AUC across folds.
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Elastic Net Logistic Regression}
\small
\textbf{Model Intuition:}
\begin{itemize}
  \item We model the probability of an \textbf{Up} move using a logistic function:
  \[
  P(Y_t = 1 \mid X_t) = \frac{1}{1 + e^{-(\beta_0 + X_t \beta)}}
  \]
  \item Coefficients \(\beta\) are maximum likelihood estimates under a regularization penalty to prevent overfitting and perform variable selection.
\end{itemize}

\vspace{0.3cm}

\textbf{Elastic Net Regularization:}
\[
\min_{\beta} \left[
  -\ell(\beta)
  + \lambda \left(
      (1 - \alpha)\frac{\|\beta\|_2^2}{2}
      + \alpha \|\beta\|_1
    \right)
\right]
\]

\begin{itemize}
  \item \(\ell(\beta)\): log-likelihood of the logistic model.
  \item \(\lambda\): overall penalty strength controlling coefficient shrinkage.
  \item \(\alpha\): mixes the two types of regularization:
  \begin{itemize}
    \item Ridge (L2): smooth shrinkage.
    \item Lasso (L1): sets some coefficients exactly to zero.
  \end{itemize}
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{Elastic Net: Tuning Procedure}
\begin{itemize}
  \item Grid search over \(\alpha \in [0, 1]\) in steps of 0.05.
  \item For each \(\alpha\), internal cross-validation via \texttt{cv.glmnet()} selects \(\lambda\).
  \item For each fold:
  \begin{enumerate}
    \item Train model on training window.
    \item Predict on validation window.
    \item Record Accuracy and AUC.
  \end{enumerate}
  \item The optimal \((\alpha, \lambda)\) combination is chosen by highest mean AUC.
  \item Final model is refitted on full training data and evaluated out-of-sample.
\end{itemize}
\end{frame}

%-------------------------------------------------------
\begin{frame}{3. Methodology: Model Assessment Strategy}
\framesubtitle{The most critical methodological slide}

\begin{block}{The Problem: Time-Series Data}
Standard \(K\)-fold CV shuffles data randomly, “peeking into the future” and violating temporal order.
This leads to overly optimistic results.
\end{block}

\pause

\begin{block}{Our Solution: Two-Level Chronological Split}
\begin{itemize}
  \item \textbf{Level 1: Train/Test Split (for Assessment)}
  \begin{itemize}
    \item Chronological 70/30 split.
    \item \textbf{Train:} 1990–2014 (used for tuning).
    \item \textbf{Test:} 2015–2025 (used once for final evaluation).
  \end{itemize}
  \pause
  \item \textbf{Level 2: Rolling-Window CV (for Tuning)}
  \begin{itemize}
    \item Within the 70\% training set, perform rolling-window validation.
    \item Simulates real-world use: train on past, predict the future.
  \end{itemize}
\end{itemize}
\end{block}
\end{frame}

\end{document}
